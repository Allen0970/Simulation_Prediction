{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d6511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29493\n"
     ]
    }
   ],
   "source": [
    "# 1. Build a dictionary that maps SUMO network information into int format and is readable by the Simulation Algorithm:\n",
    "\n",
    "# 1). Convert the node ID of the string structure to the int structure: node_to_int,\n",
    "# 2). Convert the edge ID of the string structure to the int structure: edge_to_int,\n",
    "# 3). Convert the edge ID of the int structure to the string structure: int_to_edge,\n",
    "# 4). Store the node ID and edge ID of the int structure in Manhattan_network_mapped.csv.\n",
    "\n",
    "# Read data\n",
    "directory_path = os.path.abspath('./')\n",
    "path = os.path.join(directory_path, 'Manhattan_network_raw.csv')\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "print(len(df))\n",
    "\n",
    "# Convert unique string ids of \"node_start\" and \"node_end\" to unique integers.\n",
    "# Get a list of unique nodes\n",
    "unique_nodes = pd.concat([df['node_start'], df['node_end']]).unique()\n",
    "# Create a mapping of node string id to integer\n",
    "node_to_int = {node: idx for idx, node in enumerate(unique_nodes)}\n",
    "# Replace the string ids in the dataframe\n",
    "df['node_start'] = df['node_start'].map(node_to_int)\n",
    "df['node_end'] = df['node_end'].map(node_to_int)\n",
    "\n",
    "# Convert \"edge_id\" to unique integers.\n",
    "# Create a mapping of edge string id to integer\n",
    "edge_to_int = {edge: idx for idx, edge in enumerate(df['edge_id'].unique())}\n",
    "# Replace the string ids in the dataframe\n",
    "df['edge_id'] = df['edge_id'].map(edge_to_int)\n",
    "\n",
    "# Reverse edge_to_int\n",
    "int_to_edge = {v: k for k, v in edge_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce01831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path is: /data/zxucj/Traffic_Simulation_Work/Traffic_Simulation_Data_Generation_for_Baselines/0/TraCI_output_adjusted.csv\n",
      "数据形状: (42911018, 8)\n"
     ]
    }
   ],
   "source": [
    "# 2. Feature Engineering\n",
    "\n",
    "# Define path\n",
    "path = os.path.abspath('./../../../Realistic_Event_Data_Generation_Procedure/') \n",
    "data_path = os.path.join(path,'TraCI_output_adjusted.csv') \n",
    "print('Data path is:', data_path) \n",
    "\n",
    "# Read .csv file\n",
    "dataFrame = pd.read_csv(data_path)\n",
    "selected_columns = ['Lanes_Net', 'Speed_Net', 'E_Length', 'Driving_Num', 'Travel_Time', 'Delay_Time', 'LowSpee_Time', 'Wait_Time']\n",
    "dataFrame = dataFrame[selected_columns]\n",
    "\n",
    "# Check if 'Delay_Time', 'LowSpee_Time', 'Wait_Time' have values less than 0\n",
    "for col in ['Delay_Time', 'LowSpee_Time', 'Wait_Time']:\n",
    "    if (dataFrame[col] < 0).any(): print(f\"Error: {col} contains values less than 0\")\n",
    "        \n",
    "print(\"Datashape:\", dataFrame.shape)\n",
    "\n",
    "df = dataFrame.copy()\n",
    "\n",
    "# Travel_Time should be the sum of traffic jam, low speed, and normal driving.\n",
    "df['Travel_Time'] = pd.to_numeric(df['Travel_Time'], errors='coerce') + pd.to_numeric(df['Delay_Time'], errors='coerce') + pd.to_numeric(df['LowSpee_Time'], errors='coerce')\n",
    "\n",
    "# Convert 'Delay_Time', 'LowSpee_Time', 'Wait_Time' to 0 and 1\n",
    "df[['Delay_Time', 'LowSpee_Time', 'Wait_Time']] = df[['Delay_Time', 'LowSpee_Time', 'Wait_Time']].applymap(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# The Travel_Time of the small road segment is updated to 0\n",
    "df.loc[df['E_Length'] / df['Speed_Net'] < 1, 'Travel_Time'] = 0\n",
    "df.loc[df['E_Length'] / df['Speed_Net'] < 1, 'Delay_Time'] = 0\n",
    "df.loc[df['E_Length'] / df['Speed_Net'] < 1, 'LowSpee_Time'] = 0\n",
    "\n",
    "# Convert these features to category type\n",
    "df['Delay_Time'] = df['Delay_Time'].astype('category')\n",
    "df['LowSpee_Time'] = df['LowSpee_Time'].astype('category')\n",
    "df['Wait_Time'] = df['Wait_Time'].astype('category')\n",
    "\n",
    "\n",
    "# Create an interaction term between length and speed limit (Length to Speed ​​ratio)\n",
    "df['Length_Speed_Ratio'] = df['E_Length'] / df['Speed_Net']\n",
    "\n",
    "# Logarithmically transform speed and length to reduce the impact of extreme values ​​on the model\n",
    "df['Log_E_Length'] = np.log1p(df['E_Length'])\n",
    "df['E_Length_Squared'] = df['E_Length'] ** 2\n",
    "\n",
    "# Round first, then convert to integer\n",
    "cols_to_convert = ['E_Length', 'Length_Speed_Ratio', 'Log_E_Length', 'E_Length_Squared', 'Speed_Net', 'Driving_Num']\n",
    "df[cols_to_convert] = df[cols_to_convert].round().astype(int)\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dea39af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447974\n"
     ]
    }
   ],
   "source": [
    "# Find unique input feature combination\n",
    "unique_features = df.drop_duplicates(subset=['Lanes_Net','Speed_Net','E_Length','Driving_Num','Travel_Time','Delay_Time','LowSpee_Time',\n",
    "                                             'Wait_Time','Length_Speed_Ratio','Log_E_Length','E_Length_Squared'])\n",
    "print(len(unique_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae63acbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列名完全匹配\n",
      "数据类型完全匹配\n"
     ]
    }
   ],
   "source": [
    "# Check that column names are consistent\n",
    "columns_match = list(unique_features.columns) == list(df.columns)\n",
    "if columns_match:\n",
    "    print(\"Exact column name match\")\n",
    "else:\n",
    "    print(\"Column name mismatch\")\n",
    "    print(\"unique_features column:\", list(unique_features.columns))\n",
    "    print(\"df columns:\", list(df.columns))\n",
    "\n",
    "# 检查数据类型是否一致\n",
    "dtypes_match = (unique_features.dtypes == df.dtypes).all()\n",
    "if dtypes_match:\n",
    "    print(\"Data type exactly matches\")\n",
    "else:\n",
    "    print(\"Data type mismatch\")\n",
    "    print(\"unique_features data types:\\n\", unique_features.dtypes)\n",
    "    print(\"df data types:\\n\", df.dtypes)\n",
    "\n",
    "    print(unique_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c012951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征组合和预测结果已保存到 model_catching_with_travel_time_1.txt\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model_directory_path = os.path.abspath('./../../../Model_Training_on_Manual_Allocation_Data/Model_Training/')\n",
    "model_path = os.path.join(model_directory_path, 'AutogluonModels/ag-20241207_012554')\n",
    "predictor = TabularPredictor.load(model_path, require_py_version_match=False)\n",
    "\n",
    "# Make predictions for unique feature combinations\n",
    "predictions = predictor.predict(unique_features)\n",
    "\n",
    "# Save the feature combination and prediction results to a txt file\n",
    "output_path = 'model_catching_with_travel_time_1.txt'\n",
    "with open(output_path, 'w', encoding='utf-8') as out_file:\n",
    "    for _, row in unique_features.iterrows():\n",
    "        \n",
    "        feature_data = [row['Lanes_Net'],row['Speed_Net'],row['E_Length'],row['Driving_Num'],row['Travel_Time'],row['Delay_Time'],\n",
    "                        row['LowSpee_Time'],row['Wait_Time'],row['Length_Speed_Ratio'],row['Log_E_Length'],row['E_Length_Squared']]\n",
    "        prediction = predictions.loc[_]\n",
    "        out_file.write(f\"{' '.join(map(str, feature_data))} {prediction}\\n\")\n",
    "\n",
    "print(\"Saved in file: \", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2eea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
